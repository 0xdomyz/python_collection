{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter imports\n",
    "import json\n",
    "\n",
    "# TODO: add examples of heuristic checks and simple usability metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb42d22",
   "metadata": {},
   "source": [
    "## Usability Heuristics Checklist\n",
    "- Keep interfaces consistent, observable, and forgiving.\n",
    "- Track heuristic scores to prioritize fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristics = {\n",
    "    \"visibility\": 4,  # feedback/affordances\n",
    "    \"consistency\": 4,\n",
    "    \"error_prevention\": 4,\n",
    "    \"help_docs\": 3,\n",
    "}\n",
    "\n",
    "def score(responses: dict[str, int]):\n",
    "    keys = heuristics.keys()\n",
    "    total = sum(responses.get(k, 0) for k in keys)\n",
    "    return round(total / len(keys), 2)\n",
    "\n",
    "sample = {\"visibility\": 3, \"consistency\": 4, \"error_prevention\": 2, \"help_docs\": 3}\n",
    "score(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ea6b6",
   "metadata": {},
   "source": [
    "Interpretation: average â‰¥3 is acceptable, <3 needs UX fixes. Track per-heuristic scores across releases to see regression."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
