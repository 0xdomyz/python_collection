{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c908b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter imports\n",
    "import os, threading, time, mmap\n",
    "\n",
    "# TODO: add demos for threads, locks, and simple mmap usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998c5f7",
   "metadata": {},
   "source": [
    "## Threads, Locks, and Scheduling\n",
    "- Threads share memory; use locks to guard shared state.\n",
    "- Use `time.sleep` to simulate work and observe interleaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap, tempfile, os\n",
    "\n",
    "with tempfile.TemporaryFile() as f:\n",
    "    f.write(b\"hello os mmap demo\")\n",
    "    f.flush()\n",
    "    f.seek(0)\n",
    "    with mmap.mmap(f.fileno(), length=0, access=mmap.ACCESS_READ) as mm:\n",
    "        snippet = mm[:5]\n",
    "snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3baa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, time\n",
    "\n",
    "def increment(counter, lock, rounds=50_000):\n",
    "    for _ in range(rounds):\n",
    "        with lock:\n",
    "            counter[0] += 1\n",
    "\n",
    "counter = [0]\n",
    "lock = threading.Lock()\n",
    "threads = [threading.Thread(target=increment, args=(counter, lock)) for _ in range(4)]\n",
    "for t in threads: t.start()\n",
    "for t in threads: t.join()\n",
    "counter[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a8f17",
   "metadata": {},
   "source": [
    "## Processes vs Threads (quick note)\n",
    "- Threads share memory (need locks); processes isolate memory (safer, more overhead).\n",
    "- For CPU-bound work, processes avoid the GIL; for I/O-bound, threads/async are fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3050ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures, math, time\n",
    "\n",
    "def cpu_task(n=500_000):\n",
    "    return sum(i*i for i in range(n))\n",
    "\n",
    "def bench(pool_cls, workers=4):\n",
    "    t0 = time.perf_counter()\n",
    "    with pool_cls(max_workers=workers) as pool:\n",
    "        list(pool.map(cpu_task, [200_000]*workers))\n",
    "    return round(time.perf_counter() - t0, 3)\n",
    "\n",
    "{\n",
    "    \"threads\": bench(concurrent.futures.ThreadPoolExecutor),\n",
    "    \"processes\": bench(concurrent.futures.ProcessPoolExecutor),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3662c",
   "metadata": {},
   "source": [
    "## Scheduling and I/O Notes\n",
    "- Preemptive schedulers time-slice threads; `sleep` yields voluntarily.\n",
    "- CPU-bound work benefits from fewer runnable threads; I/O-bound can multiplex many.\n",
    "- Disk/network I/O: use buffers; `fsync`/`flush` when durability matters; async I/O to avoid blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bb62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffered vs flushed file write demo\n",
    "import os, tempfile, time\n",
    "\n",
    "data = b\"x\" * 1024\n",
    "with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "    path = f.name\n",
    "    f.write(data)\n",
    "    f.flush()  # buffered flush\n",
    "    os.fsync(f.fileno())  # force to disk\n",
    "\n",
    "size = os.path.getsize(path)\n",
    "os.remove(path)\n",
    "size"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
